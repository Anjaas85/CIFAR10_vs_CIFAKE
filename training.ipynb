{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING THE MODEL - this is the training for final densnet model\n",
    "\n",
    "#imports \n",
    "import os\n",
    "from models.densenet_model import create_densenet\n",
    "from utils.data_loader import create_dataloaders, create_test_loader\n",
    "from utils.evaluation import evaluate_model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, f1_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from utils.early_stopping import EarlyStopping\n",
    "\n",
    "#device - (we used collab gpu)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#data\n",
    "data_dir = 'data'\n",
    "dataloaders = create_dataloaders(batch_size=32)\n",
    "test_loader = create_test_loader(batch_size=32)\n",
    "\n",
    "model = create_densenet(num_classes=2).to(device)\n",
    "\n",
    "#loss function and oadam optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4,weight_decay = 1e-5)\n",
    "\n",
    "#learnin rate\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode = 'min', factor = 0.5, patience = 3, verbose = True)\n",
    "\n",
    "\n",
    "\n",
    "#TRAINING MODEL\n",
    "def train_model(model, criterion, optimizer, dataloaders, num_epochs=20, device='cuda', patience=10):\n",
    "    #preaparation of the folder\n",
    "    metrics_file_path = os.path.join('metrics', 'metrics_by_epoch.txt')\n",
    "    os.makedirs('metrics', exist_ok=True)\n",
    "    os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "    #anouncing metrics that we're going to save\n",
    "    metrics_data = {\n",
    "        \"precision_recall\": [],\n",
    "        \"f1_scores\": [],\n",
    "        \"val_probs\": [],\n",
    "        \"val_labels\": [],\n",
    "        \"confusion_matrices\": [],\n",
    "        \"epoch_metrics\": []\n",
    "    }\n",
    "\n",
    "    # scheduler and early stopping\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
    "    early_stopping = EarlyStopping(patience=patience, checkpoint_path='checkpoints/best_model.pth')\n",
    "\n",
    "\n",
    "    with open(metrics_file_path, 'w') as f:\n",
    "        f.write(f'Epoch\\tPhase\\tLoss\\tAccuracy\\n')\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "            print('-' * 10)\n",
    "\n",
    "\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  #training mode\n",
    "                else:\n",
    "                    model.eval()  #validation mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "                all_labels = []\n",
    "                all_probs = []\n",
    "\n",
    "                #go through batches\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    \n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        # go forward\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "\n",
    "                        # if it's training phase we need to update weights\n",
    "                        if phase == 'train':\n",
    "                            loss.backward() \n",
    "                            optimizer.step() \n",
    "\n",
    "                \n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                    all_labels.extend(labels.cpu().numpy().tolist())\n",
    "                    all_probs.extend(probs.detach().cpu().numpy().tolist())\n",
    "\n",
    "                #epoch metrics\n",
    "                epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "                epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "                f.write(f'{epoch+1}\\t{phase}\\t{epoch_loss:.4f}\\t{epoch_acc:.4f}\\n')\n",
    "\n",
    "                if phase == 'val':\n",
    "                    scheduler.step(epoch_loss)\n",
    "\n",
    "                    # metrics\n",
    "                    precision, recall, thresholds = precision_recall_curve(all_labels, all_probs)\n",
    "                    f1 = f1_score(all_labels, np.round(all_probs))\n",
    "                    confusion_mat = confusion_matrix(all_labels, np.round(all_probs))\n",
    "\n",
    "                    metrics_data[\"precision_recall\"].append({\n",
    "                        \"precision\": precision.tolist(),\n",
    "                        \"recall\": recall.tolist(),\n",
    "                        \"thresholds\": thresholds.tolist(),\n",
    "                    })\n",
    "                    metrics_data[\"f1_scores\"].append(float(f1))\n",
    "                    metrics_data[\"val_probs\"].append(all_probs)\n",
    "                    metrics_data[\"val_labels\"].append(all_labels)\n",
    "                    metrics_data[\"confusion_matrices\"].append(confusion_mat.tolist())\n",
    "                    metrics_data[\"epoch_metrics\"].append({\n",
    "                        \"epoch\": epoch+1,\n",
    "                        \"loss\": float(epoch_loss),\n",
    "                        \"accuracy\": float(epoch_acc)\n",
    "                    })\n",
    "\n",
    "                    # based on val loss, early stopping, we never reached patience\n",
    "                    early_stopping(epoch_loss, model)\n",
    "\n",
    "                    if early_stopping.early_stop:\n",
    "                        print(\"Early stopping triggered.\")\n",
    "                        break\n",
    "            # if early stopping is activated we need to stop loop (we suppose it works - never reached)\n",
    "            if early_stopping.early_stop:\n",
    "                break\n",
    "\n",
    "    #extensive metrics save\n",
    "    with open(os.path.join('metrics', 'metrics_data.json'), 'w') as json_file:\n",
    "        json.dump(metrics_data, json_file, indent=4)\n",
    "\n",
    "    #model saving\n",
    "    model_save_path = os.path.join('checkpoints', 'densenet_ai_vs_authentic.pth')\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved at {model_save_path}\")\n",
    "\n",
    "    print(f\"Metrics saved in {metrics_file_path} and metrics_data.json\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "#training of model\n",
    "trained_model = train_model(model, criterion, optimizer, dataloaders, num_epochs=20, device=device, patience=10)\n",
    "\n",
    "\n",
    "\n",
    "#saving the model\n",
    "torch.save(trained_model.state_dict(), 'checkpoints/densenet_ai_vs_authentic.pth')\n",
    "print(\"Model trained and saved!\")\n",
    "\n",
    "#final evaluation for validation and test set\n",
    "print(\"Evaluating on validation set:\")\n",
    "evaluate_model(trained_model, dataloaders['val'], device,\"validation\")\n",
    "\n",
    "print(\"Evaluating on test set:\")\n",
    "evaluate_model(trained_model, test_loader, device, \"test\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
